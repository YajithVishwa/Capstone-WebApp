{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SANKARASUBRAMANIYAN\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "# import spacy\n",
    "from sklearn.decomposition import PCA\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    input  :  word list of a sentence\n",
    "    output :  processed word list of the sentence\n",
    "'''\n",
    "\n",
    "def remove_stopwords(sentence): \n",
    "    processed = []\n",
    "    for word in sentence:\n",
    "        if word not in stopwords.words('english'):\n",
    "            processed.append(word)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_vec(vect, word_list, size, model):\n",
    "    # Performing Vector Addition\n",
    "    processed = simple_preprocess(vect.lower())\n",
    "    docVector = np.zeros(size)\n",
    "    for word in processed:\n",
    "        if word in word_list:\n",
    "            docVector = np.add(docVector, model.wv.get_vector(word))\n",
    "    return docVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(A, B):\n",
    "    '''\n",
    "    Input:\n",
    "        A: a numpy array which corresponds to a word vector\n",
    "        B: A numpy array which corresponds to a word vector\n",
    "    Output:\n",
    "        cos: numerical number representing the cosine similarity between A and B.\n",
    "    '''\n",
    "    \n",
    "    dot = np.dot(A,B)\n",
    "    norma = np.sqrt(np.dot(A,A))\n",
    "    normb = np.sqrt(np.dot(B,B))\n",
    "    cos = dot / (norma*normb)\n",
    "\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../OOPS DataSet Capstone - Sheet1.csv')\n",
    "sentences = []\n",
    "for index, value in df['text'].items():\n",
    "    lines = value.split('.')\n",
    "    for l in lines:\n",
    "        line = l.strip()\n",
    "        line = list(set(simple_preprocess(line)))\n",
    "        sentences.append(line)\n",
    "sentences = [ele for ele in sentences if ele != []]\n",
    "sentences = [remove_stopwords(ele) for ele in sentences]\n",
    "processed_sentences = sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = Word2Vec(window=10,\n",
    "    min_count=2,\n",
    "    workers=4)\n",
    "word2vec.build_vocab(processed_sentences, progress_per=1000)\n",
    "word2vec.train(processed_sentences, total_examples=word2vec.corpus_count, epochs=word2vec.epochs)\n",
    "\n",
    "word_list = word2vec.wv.vocab\n",
    "word_list = list(word_list.keys())\n",
    "X = []\n",
    "for word in word_list:\n",
    "    X.append(word2vec.wv.get_vector(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.1603856e-03,  1.5921918e-03, -1.2394958e-03,  1.7883796e-03,\n",
       "       -2.8283536e-03, -3.3068170e-03, -1.8937411e-03,  4.6930420e-03,\n",
       "        5.5075935e-03, -2.2822230e-03, -3.8919998e-03, -4.0077786e-03,\n",
       "       -4.1251937e-03,  4.4413013e-03, -1.2605322e-04,  1.1332654e-04,\n",
       "        1.8688955e-03,  4.0708045e-03,  2.3878686e-04, -9.8954581e-05,\n",
       "       -2.1594528e-03, -2.1043813e-04,  4.5751571e-03, -3.8466335e-03,\n",
       "       -9.6808595e-04,  2.6526139e-03,  2.8365059e-03, -1.5282293e-03,\n",
       "       -2.0992036e-03,  4.0526828e-03, -2.6974308e-03, -1.4509683e-03,\n",
       "        2.3959980e-03,  1.8345255e-03,  7.0129480e-04,  1.5585661e-03,\n",
       "        4.1427296e-03,  1.7751551e-03,  4.0892488e-04, -2.3791678e-03,\n",
       "       -3.6442443e-04, -3.5762172e-03, -2.1894162e-03, -3.9240546e-03,\n",
       "        4.3779477e-03, -3.3614188e-03,  1.1156620e-03,  4.0065576e-03,\n",
       "        2.5993821e-03, -2.3393170e-03,  6.1229384e-04, -1.2450933e-03,\n",
       "        3.4097352e-03, -1.6111290e-03, -3.4407666e-03,  1.2851272e-04,\n",
       "       -4.3313969e-03,  5.2544880e-03,  2.3749657e-03, -4.7253836e-03,\n",
       "        8.1507355e-04,  7.0200796e-04,  5.5099702e-03,  1.3757367e-03,\n",
       "       -1.0297862e-03, -1.2455805e-04, -4.8780800e-03,  9.4579905e-04,\n",
       "        1.7967750e-03, -2.0706668e-04,  1.6250419e-04,  5.0800689e-04,\n",
       "       -3.3390176e-04,  1.4560654e-04,  1.5788057e-04, -4.4668815e-03,\n",
       "       -2.9258642e-03,  8.6128950e-04,  3.5967540e-03,  4.1085542e-03,\n",
       "        1.9211669e-03,  3.7785445e-03, -3.3156064e-03, -3.0865986e-03,\n",
       "       -3.9923410e-03, -5.0937710e-03,  1.2998153e-03, -1.6782156e-03,\n",
       "        6.9249283e-05,  2.4838038e-03, -1.5776356e-03, -1.1781019e-03,\n",
       "        3.8660569e-03, -1.3826623e-03, -3.1137187e-03,  3.5325757e-03,\n",
       "        2.2125817e-04,  3.3550770e-03,  3.5525840e-03, -2.3126286e-03],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.get_vector('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_similarity(answer_key, student_answer):\n",
    "    VECTOR_SIZE = len(X[0])\n",
    "    answer_key_vector = doc_to_vec(answer_key, word_list, VECTOR_SIZE, word2vec)\n",
    "    student_answer_vector = doc_to_vec(student_answer, word_list, VECTOR_SIZE, word2vec)\n",
    "    sim_score = cosine_similarity(answer_key_vector, student_answer_vector)*100\n",
    "    return sim_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SANKARASUBRAMANIYAN\\AppData\\Roaming\\nltk_data\n",
      "[nltk_data]     ...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df['text'].values\n",
    "topics = df['topic'].values\n",
    "\n",
    "sentences = []\n",
    "for index, value in df['text'].items():\n",
    "    lines = value.split('.')\n",
    "    for l in lines:\n",
    "        line = l.strip()\n",
    "        sentences.append(line)\n",
    "\n",
    "train_data = [ele for ele in sentences if ele != [] and ele !='' and ele!=' ']\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(train_data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ExtendedC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 100\n",
    "vec_size = 300\n",
    "alpha = 0.025\n",
    "\n",
    "model = Doc2Vec(size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=2,\n",
    "                negative=5,\n",
    "                dm =1) # dm=1 means distributed memory PV-DM\n",
    "  \n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    # print('iteration {0}'.format(epoch))\n",
    "    model.train(tagged_data,\n",
    "                total_examples=model.corpus_count,\n",
    "                epochs=model.iter)\n",
    "    # decrease the learning rate\n",
    "    model.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model.min_alpha = model.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2vec_similarity(answer_key, student_answer):\n",
    "    A = model.infer_vector(answer_key.split())\n",
    "    B = model.infer_vector(student_answer.split())\n",
    "    return cosine_similarity(A,B)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flask API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flask\n",
    "from flask import request, jsonify\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flask_cors.extension.CORS at 0x1866f8cfec8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flask_cors import CORS\n",
    "app = flask.Flask(__name__)\n",
    "CORS(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/', methods=['GET'])\n",
    "def welcome():\n",
    "    return \"<h1>Auto Grading</h1> <br/> <p> This site is a prototype API for <h3>Capstone Design Project</h3> </p>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/grades/word2vec', methods=['GET', 'POST'])\n",
    "def word2vec_grade():\n",
    "    if request.method == 'GET':\n",
    "        return \"<h1>Grading API</h1> <br/>\"  \n",
    "    elif request.method == 'POST':\n",
    "#         doc_key = request.form['doc_key']\n",
    "#         doc_ans = request.form['doc_ans']\n",
    "        json_data = request.get_json()\n",
    "        doc_key = json_data['given_ans']\n",
    "        doc_ans = json_data['student_ans']\n",
    "        grade = word2vec_similarity(doc_key, doc_ans)\n",
    "        response = {'grader':'word2vec','grade':grade}\n",
    "        return json.dumps(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/grades/doc2vec', methods=['GET', 'POST'])\n",
    "def doc2vec():\n",
    "    if request.method == 'GET':\n",
    "        return \"<h1>Grading API</h1> <br/>\"  \n",
    "    elif request.method == 'POST':\n",
    "        json_data = request.get_json()\n",
    "        doc_key = json_data['given_ans']\n",
    "        doc_ans = json_data['student_ans']\n",
    "        grade = doc2vec_similarity(doc_key, doc_ans)\n",
    "        response = {'grader':'doc2vec','grade':grade}\n",
    "        return json.dumps(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:4458/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [17/Dec/2021 19:37:46] \"OPTIONS /grades/word2vec HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2021 19:37:46] \"POST /grades/word2vec HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2021 19:37:50] \"OPTIONS /grades/doc2vec HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Dec/2021 19:37:50] \"POST /grades/doc2vec HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app.run(port=4458)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.28183609051862"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_similarity(\n",
    "    \"Polymorphism is the method in an object-oriented programming language that performs different things as per the object which calls it\", \n",
    "    \"Polymorphism performs a single action in different ways as per the object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = \"Polymorphism is the method in an object-oriented programming language that performs different things as per the object which calls it\".split()\n",
    "len(model.infer_vector(list_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = \"Polymorphism performs a single action in different ways as per the object\".split()\n",
    "len(model.infer_vector(list_of_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_similarity(\"Class is user-defined data types that act as the blueprint for individual objects, attributes, and methods\", \n",
    "    \"A class is a blueprint for creating objects, providing initial values for state and implementations of behavior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d47d8c10fe71>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "word2vec.wv.get_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gensim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-4600b3520fb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'gensim' is not defined"
     ]
    }
   ],
   "source": [
    "gensim.model__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
